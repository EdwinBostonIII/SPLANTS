# SPLANTS Marketing Engine

## AI-Powered Content Generation for SPLANTS Custom Pants

![Version](https://img.shields.io/badge/version-2.1-blue)
![Status](https://img.shields.io/badge/status-production--ready-green)
![Cost](https://img.shields.io/badge/monthly%20cost-$35--80-orange)

---

## Table of Contents

1. [What Is This?](#what-is-this)
2. [What You Get](#what-you-get)
3. [How Much Does It Cost?](#how-much-does-it-cost)
4. [What You Need](#what-you-need)
5. [Installation Guide](#installation-guide)
6. [First-Time Setup](#first-time-setup)
7. [How to Use It](#how-to-use-it)
8. [Understanding The Tools](#understanding-the-tools)
9. [Common Tasks](#common-tasks)
10. [Troubleshooting](#troubleshooting)
11. [Frequently Asked Questions](#frequently-asked-questions)
12. [Glossary of Terms](#glossary-of-terms)

---

## What Is This?

The SPLANTS Marketing Engine is an AI-powered content generation system designed specifically for the SPLANTS brand. This system automates the creation of marketing content for custom paint-splatter pants with Jackson Pollock-inspired patterns.

The engine provides:
- AI-generated marketing content using GPT-4 technology
- Automated blog posts, social media content, emails, and advertisements
- Search engine optimization (SEO) for improved online visibility
- Performance tracking and analytics
- Cost-effective operation at $35-80 per month

### Comparison

**Traditional Approach:**
- Freelance writer: $200 per blog post
- Delivery time: 3-5 days
- Social media content: $150 additional
- SEO optimization: $300 additional
- Total monthly cost: $650+

**SPLANTS Marketing Engine:**
- Unlimited content generation
- Instant delivery (30 seconds per piece)
- Integrated SEO optimization
- Total monthly cost: $35-80

---

 **Small Business Owners** who need marketing but can't afford an agency
## What You Get

### Core Features (Included)

| Feature | What It Does | Value |
|---------|-------------|-------|
| **AI Content Generation** | Creates blog posts, social media content, emails, ads, and more using GPT-4 | Worth $500-2,000/month if hired |
| **SEO Optimization** | Makes your content rank better on Google | Worth $300-1,000/month |
| **Quality Scoring** | Rates each piece of content so you know it's good | Worth $200/month |
| **Multi-Platform Publishing** | Post to Twitter, LinkedIn, Instagram, Facebook, and more | Worth $500/month |
| **Storage & Management** | Keeps all your content organized in a database | Worth $50/month |

### FREE Bonus Features (No Extra Cost)

| Feature | What It Does | How It Helps You |
|---------|-------------|------------------|
| ** Analytics Dashboard** | Shows what content works best | Make smarter marketing decisions |
| ** A/B Testing** | Creates multiple versions to test which performs better | Increase engagement by 20-30% |
| ** Content Templates** | Pre-made structures for proven content types | Save 2-3 hours per piece |
| ** Cost Control** | Monitors spending and prevents budget overruns | Never get surprised by bills |
| ** Webhooks** | Connect to Zapier for automation | Integrate with 5,000+ apps |
| ** Smart Hashtags** | Auto-generates relevant hashtags | Better social media reach |
| ** Platform Optimization** | Adjusts content for each platform automatically | Content performs better |

### Optional Premium Features

| Feature | Extra Cost | What You Get |
|---------|-----------|--------------|
| **Redis Caching** | +$10-15/month | Reduces AI costs by 30-50% |
| **Multi-Model AI** | +$0.02-0.05 per request | 20-30% higher quality using GPT-4 + Claude |
| **Auto-Publishing** | Free-$30/month | Actually posts to social media for you |

---

##  How Much Does It Cost?

### Monthly Cost Breakdown

| Item | Cost | What It's For |
|------|------|---------------|
| **Server (Computer to run it on)** | $5-15/month | Keeps the system running 24/7 |
| **Database (Storage for content)** | $5-10/month | Stores all your content |
| **AI Usage (GPT-4 costs)** | $15-50/month | Creating the actual content |
| **Optional: Redis Cache** | $10-15/month | Makes it 30-50% cheaper to run |
| **TOTAL** | **$35-80/month** | Complete marketing system |

### Cost Comparison

| Solution | Monthly Cost | What You Get |
|----------|-------------|--------------|
| **SPLANTS** | $35-80 | Unlimited content, all features |
| **Hiring a Writer** | $500-2,000 | 5-20 articles only |
| **Marketing Agency** | $2,000-10,000 | Full service (if you can afford it) |
| **HubSpot** | $800-3,200 | Marketing automation platform |
| **Jasper.ai** | $49-125 | AI writing only (no publishing, analytics) |

** Bottom Line:** SPLANTS saves you 90-95% compared to traditional solutions!

---

##  What You Need

### 1. A Computer

You can use:
- **Windows** (Windows 10 or newer)
- **Mac** (macOS 10.14 or newer)
- **Linux** (Ubuntu, Debian, etc.)

**Minimum Requirements:**
- 4GB RAM (memory)
- 20GB free disk space
- Internet connection

### 2. Three Free Accounts

#### A. Docker Account (Free)
**What is Docker?** Think of it as a "shipping container" for software. It packages everything the program needs to run.

**Where to get it:** [docker.com](https://docker.com)
**Cost:** Free
**Time to setup:** 5 minutes

#### B. OpenAI Account (Paid but cheap)
**What is OpenAI?** The company that makes GPT-4, the AI that creates your content.

**Where to get it:** [platform.openai.com](https://platform.openai.com)
**Cost:** ~$15-50/month for content generation
**Time to setup:** 5 minutes

#### C. A Text Editor (Free)
**What is it?** A program to edit configuration files.

**Recommendations:**
- **Windows:** Notepad (built-in) or [Notepad++](https://notepad-plus-plus.org/)
- **Mac:** TextEdit (built-in) or [VS Code](https://code.visualstudio.com/)
- **Linux:** nano (built-in) or gedit

---

##  Installation Guide (Step-by-Step)

### Step 1: Install Docker (The "Container" for the Software)

Docker is a tool that runs the software in an isolated environment. You only need to install it once.

#### For Windows:

1. **Download Docker Desktop:**
   - Go to [docker.com/get-started](https://docker.com/get-started)
   - Click "Download for Windows"
   - File size: ~500MB (may take 5-10 minutes to download)

2. **Install Docker Desktop:**
   - Double-click the downloaded file
   - Follow the installation wizard (click "Next" ‚Üí "Next" ‚Üí "Install")
   - Restart your computer when prompted

3. **Verify It's Working:**
   - Look for a whale icon in your system tray (bottom-right corner)
   - If you see it, Docker is running! 

**Troubleshooting:** If Docker doesn't start, you may need to enable virtualization in your BIOS. [See detailed guide here](#troubleshooting-docker-wont-start-on-windows)

#### For Mac:

1. **Download Docker Desktop:**
   - Go to [docker.com/get-started](https://docker.com/get-started)
   - Click "Download for Mac"
   - Choose "Mac with Intel chip" or "Mac with Apple chip" (M1/M2)

2. **Install Docker Desktop:**
   - Open the downloaded `.dmg` file
   - Drag Docker to your Applications folder
   - Open Docker from Applications

3. **Verify It's Working:**
   - Look for a whale icon in your menu bar (top-right)
   - If you see it, Docker is running! 

#### For Linux (Ubuntu/Debian):

1. **Open Terminal** (Press `Ctrl + Alt + T`)

2. **Run These Commands** (copy and paste one at a time):

```bash
# Download Docker installation script
curl -fsSL https://get.docker.com -o get-docker.sh

# Run the installation script
sudo sh get-docker.sh

# Add your user to the docker group (so you don't need sudo)
sudo usermod -aG docker $USER

# Install Docker Compose
sudo apt install docker-compose -y
```

3. **Restart Your Computer**

4. **Verify It's Working:**
```bash
docker --version
```
You should see something like "Docker version 24.0.6"

---

### Step 2: Get Your OpenAI API Key

OpenAI is the company that provides the AI (GPT-4) that creates your content.

**Think of the API key like a password** that lets this program use OpenAI's AI.

#### Detailed Steps:

1. **Create an OpenAI Account:**
   - Go to [platform.openai.com/signup](https://platform.openai.com/signup)
   - Sign up with your email
   - Verify your email address

2. **Add Billing Information:**
   - Go to [platform.openai.com/account/billing](https://platform.openai.com/account/billing)
   - Click "Add payment method"
   - Add a credit card
   - **Add $20 credit** (this will generate ~600-700 pieces of content)

3. **Create an API Key:**
   - Go to [platform.openai.com/api-keys](https://platform.openai.com/api-keys)
   - Click "Create new secret key"
   - **IMPORTANT:** Copy the key immediately! It starts with `sk-`
   - Save it in a safe place (you can't see it again)

**Example API Key:** `sk-proj-abc123XYZ...` (yours will be longer)

** Pro Tip:** Set up a spending limit in OpenAI's billing settings to prevent unexpected charges.

---

### Step 3: Download SPLANTS Marketing Engine

You need to get the software files onto your computer.

#### Option A: Using Git (Recommended)

**What is Git?** A tool for downloading and managing code.

1. **Install Git:**
   - **Windows:** Download from [git-scm.com](https://git-scm.com)
   - **Mac:** Open Terminal and type `git --version` (it will install automatically)
   - **Linux:** `sudo apt install git`

2. **Download SPLANTS:**
```bash
# Open Terminal (Mac/Linux) or Command Prompt (Windows)
cd Desktop
git clone [repository URL].git
cd SPLANTS
```

#### Option B: Download ZIP (Easier)

1. Go to [[repository URL]]([repository URL])
2. Click the green "Code" button
3. Click "Download ZIP"
4. Extract the ZIP file to your Desktop
5. Rename the folder to `SPLANTS`

---

##  First-Time Setup

The SPLANTS Marketing Engine now includes an **interactive setup wizard** that guides you through the entire configuration process. No need to manually edit files!

### Quick Start (Recommended)

1. **Open Terminal/Command Prompt** in the SPLANTS folder:
   - **Windows:** Right-click in the folder ‚Üí "Open in Terminal" or "Open Command Prompt here"
   - **Mac:** Right-click folder ‚Üí Services ‚Üí "New Terminal at Folder"
   - **Linux:** Right-click ‚Üí "Open in Terminal"

2. **Run the setup wizard:**

```bash
make start
```

That's it! The wizard will:
- ‚úÖ Check if Docker is installed and running
- ‚úÖ Ask for your OpenAI API key
- ‚úÖ Generate a secure system API key (or let you provide your own)
- ‚úÖ Set up your monthly budget preference
- ‚úÖ Create the `.env` configuration file automatically
- ‚úÖ Build and start all services
- ‚úÖ Show you your generated API key (save it!)

3. **Access the system:**

Open your web browser and go to:
```
http://localhost:3000
```

**You should see:** The SPLANTS Marketing Engine web interface! 

---

##  Verify Your Installation

After setup, verify everything is working correctly.

### Quick Verification

The system includes automated verification scripts:

#### Option 1: Pre-Installation System Check

Before installing, verify your system meets all requirements:

```bash
./scripts_check-system.sh
```

This checks:
- ‚úÖ Operating system compatibility
- ‚úÖ Docker installation and version
- ‚úÖ Docker Compose availability
- ‚úÖ System resources (RAM, disk space)
- ‚úÖ Network connectivity
- ‚úÖ Required ports availability

#### Option 2: Post-Installation Verification

After setup, verify the installation is working:

```bash
./scripts_verify-installation.sh
```

This validates:
- ‚úÖ Configuration file exists and is valid
- ‚úÖ Docker containers are running
- ‚úÖ Services are healthy (database, API, web UI)
- ‚úÖ API endpoints respond correctly
- ‚úÖ Database connection works
- ‚úÖ No errors in recent logs

Both scripts provide clear pass/fail feedback and actionable remediation steps.

### Manual Verification

If you prefer to verify manually:

1. **Check services are running:**
   ```bash
   make status
   ```

2. **Test the API:**
   ```bash
   make test
   ```

3. **Access the web interface:**
   Open http://localhost:3000 in your browser

---

### Manual Setup (Alternative Method)

If you prefer to configure manually or the wizard doesn't work:

1. **Create Your Configuration File**

   ```bash
   cp .env.example .env
   ```

2. **Edit the `.env` file** and add:
   - Your OpenAI API key (from https://platform.openai.com/api-keys)
   - A secure system API key (at least 12 characters)
   - Your monthly budget (optional, recommended: $50)

3. **Start the system:**

   ```bash
   make start
   ```
   
   Or directly with Docker Compose:
   ```bash
   docker compose up -d   # Modern Docker Desktop (v2.x)
   # OR
   docker-compose up -d   # Older standalone version
   ```

---

##  Managing the System

The Makefile provides simple commands for all operations:

### Essential Commands

```bash
make start     # First-time setup and start (runs interactive wizard)
make stop      # Stop all services
make restart   # Restart all services
make logs      # View application logs (live)
make status    # Check service status
make test      # Run API tests to verify everything works
```

### Maintenance Commands

```bash
make backup              # Backup database
make restore file=<file> # Restore database from backup
make update              # Pull latest changes and rebuild
make clean               # Remove all data (WARNING: deletes everything!)
```

### Development Commands

```bash
make dev       # Start in development mode (with logs)
make build     # Build Docker images
make rebuild   # Rebuild Docker images (no cache)
make monitor   # Monitor resource usage
```

### Troubleshooting

If something isn't working:

1. **Run the test suite:**
   ```bash
   make test
   ```
   
   This validates the API contract between backend and frontend. If tests pass, the problem is likely in the frontend. If they fail, it's in the backend.

2. **Check the logs:**
   ```bash
   make logs
   ```

3. **Verify services are running:**
   ```bash
   make status
   ```

4. **See detailed troubleshooting:**
   - [TROUBLESHOOTING.md](TROUBLESHOOTING.md) - Common problems and solutions
   - [FAQ.md](FAQ.md) - Frequently asked questions

---

##  How to Use It

### Method 1: Using the Interactive Web Interface (Easiest)

1. **Open the API Documentation:**
   ```
   http://localhost:3000/api/docs
   ```

2. **You'll see a beautiful interface** with all available features

3. **To generate content:**
   - Find "POST /v1/generate" in the list
   - Click on it to expand
   - Click "Try it out"
   - Fill in the form:
     - **content_type:** Select "blog"
     - **topic:** "5 Ways AI Helps Small Businesses"
     - **keywords:** ["AI", "small business", "automation"]
     - **tone:** "professional"
     - **length:** 800
   - Click "Execute"

4. **See your generated content!** It appears in the "Response body" section

### Method 2: Using the Test Script

We've included a test script that generates several types of content:

```bash
python test_api.py
```

This will:
-  Generate a blog post
-  Create social media posts
-  Generate email content
-  Show you analytics

### Method 3: Using Your Own Code (For Developers)

**Python Example:**
```python
import requests

# Your configuration
API_KEY = "your-api-key-here"  # From your .env file
BASE_URL = "http://localhost:3000/api"

# Make a request
response = requests.post(
    f"{BASE_URL}/v1/generate",
    headers={
        "X-API-Key": API_KEY,
        "Content-Type": "application/json"
    },
    json={
        "content_type": "blog",
        "topic": "10 Marketing Tips for Small Business",
        "keywords": ["marketing", "small business", "tips"],
        "tone": "professional",
        "length": 800
    }
)

# Get the result
content = response.json()
print(f"Quality Score: {content['quality_score']}")
print(f"Content: {content['content']}")
```

**JavaScript Example:**
```javascript
const axios = require('axios');

const API_KEY = 'your-api-key-here';
const BASE_URL = 'http://localhost:3000/api';

async function generateContent() {
  const response = await axios.post(
    `${BASE_URL}/v1/generate`,
    {
      content_type: 'blog',
      topic: '10 Marketing Tips for Small Business',
      keywords: ['marketing', 'small business', 'tips'],
      tone: 'professional',
      length: 800
    },
    {
      headers: {
        'X-API-Key': API_KEY,
        'Content-Type': 'application/json'
      }
    }
  );

  console.log('Quality Score:', response.data.quality_score);
  console.log('Content:', response.data.content);
}

generateContent();
```

---

##  Understanding The Tools

### What Each Tool Does (Simple Explanations)

#### Docker 
**What it is:** A way to package and run software in isolated "containers"

**Why you need it:** Makes sure the software runs the same way on every computer

**Real-world analogy:** Like a shipping container that has everything inside it - no matter where it goes, everything needed is already packed in

**What it costs:** Free

---

#### PostgreSQL üóÑÔ∏è
**What it is:** A database (think of it as a organized filing cabinet for data)

**Why you need it:** Stores all your generated content, analytics, and settings

**Real-world analogy:** Like a digital filing cabinet that organizes your content by date, type, quality, etc.

**What it costs:** Free (included)

---

#### FastAPI ‚ö°
**What it is:** A modern web framework that creates the API

**Why you need it:** This is what creates the website interface where you interact with the AI

**Real-world analogy:** Like the control panel or dashboard of a car - it gives you buttons and screens to control the engine (the AI)

**What it costs:** Free (included)

---

#### OpenAI GPT-4 
**What it is:** The actual AI that writes content

**Why you need it:** This is the "brain" that generates marketing content

**Real-world analogy:** Like hiring a super-smart writer who can write anything in seconds

**What it costs:** ~$0.03 per piece of content

---

#### Redis (Optional) 
**What it is:** A super-fast cache (temporary storage)

**Why you might want it:** Reduces costs by 30-50% by remembering similar requests

**Real-world analogy:** Like having a photographic memory - if you ask the same question twice, it remembers the answer instead of thinking from scratch

**What it costs:** $10-15/month extra

---

### How They Work Together

```
You ‚Üí [Web Browser] ‚Üí [FastAPI] ‚Üí [GPT-4 AI] ‚Üí [PostgreSQL Database]
                          ‚Üì
                      Content Created
                          ‚Üì
                    [Stored & Analyzed]
                          ‚Üì
                     [Shows Results]
```

**Simple Flow:**
1. **You** open the web browser and request content
2. **FastAPI** receives your request
3. **GPT-4 AI** generates the content
4. **PostgreSQL** stores the content
5. **You** see the results!

---

##  Common Tasks

### Task 1: Generate a Blog Post

**Goal:** Create a 800-word blog post about AI marketing

**Steps:**
1. Go to `http://localhost:3000` or `http://localhost:3000/api/docs`
2. Find "POST /v1/generate"
3. Click "Try it out"
4. Enter:
   ```json
   {
     "content_type": "blog",
     "topic": "How AI is Transforming Small Business Marketing in 2024",
     "keywords": ["AI", "marketing", "small business", "2024"],
     "tone": "professional",
     "length": 800,
     "seo_optimize": true
   }
   ```
5. Click "Execute"
6. Copy your blog post from the response!

**Time:** 30 seconds
**Cost:** ~$0.03

---

### Task 2: Create Social Media Posts

**Goal:** Create posts for Twitter and LinkedIn

**Steps:**
1. Go to the API documentation
2. Generate Twitter post:
   ```json
   {
     "content_type": "social_post",
     "topic": "Announcing our new AI marketing tools!",
     "platform": "twitter",
     "tone": "enthusiastic",
     "include_hashtags": true
   }
   ```
3. Generate LinkedIn post:
   ```json
   {
     "content_type": "social_post",
     "topic": "How we're using AI to revolutionize marketing",
     "platform": "linkedin",
     "tone": "professional",
     "include_hashtags": true
   }
   ```

**Time:** 1 minute for both
**Cost:** ~$0.05 total

---

### Task 3: Check Your Analytics

**Goal:** See how much content you've created and costs

**Steps:**
1. Go to `http://localhost:3000` and check the Dashboard
2. Find "GET /v1/analytics/dashboard"
3. Click "Try it out"
4. Enter `days: 30` (to see last 30 days)
5. Click "Execute"

**You'll see:**
- Total content generated
- Average quality scores
- Total costs
- ROI calculations
- Content breakdown by type

---

### Task 4: Control Your Costs

**Goal:** Check how much you've spent this month

**Steps:**
1. Go to `http://localhost:3000` and check the Dashboard
2. Find "GET /v1/costs/usage"
3. Click "Try it out"
4. Click "Execute"

**You'll see:**
- Monthly spending
- Budget remaining
- Daily usage
- Projected monthly cost
- Alerts if you're approaching limits

---

### Task 5: Use Content Templates

**Goal:** Generate content using proven templates

**Steps:**
1. See available templates:
   - Go to `http://localhost:3000` or API docs at `http://localhost:3000/api/docs`
   - Find "GET /v1/templates"
   - Click "Execute"

2. Choose a template (e.g., "blog_listicle")

3. Generate from template:
   - Find "POST /v1/templates/generate"
   - Enter:
   ```json
   {
     "template_id": "blog_listicle",
     "variables": {
       "number": "10",
       "topic": "AI Marketing Tips",
       "items": ["Automation", "Content", "Analytics"]
     },
     "use_ai": true
   }
   ```

---

### Task 6: Create A/B Test Variants

**Goal:** Test which version of content performs better

**Steps:**
1. Generate variants:
   ```json
   {
     "content_type": "email",
     "topic": "Welcome to our marketing platform!",
     "tone": "friendly",
     "generate_variants": true
   }
   ```

2. Get the `content_id` from the response

3. View all variants:
   - Find "GET /v1/ab-test/{content_id}"
   - Enter your content_id
   - Click "Execute"

**You'll get:** 3 different versions to test!

---

### Task 7: Configure Webhooks for Automation

**Goal:** Set up automatic notifications and integrations with Zapier, Make, or other services

**What are webhooks?**
- Automatic notifications sent when events happen in SPLANTS
- Connect to thousands of apps via Zapier, Make, or IFTTT
- No code required!

**Steps:**

1. **Go to the Settings page:**
   - Open `http://localhost:3000` in your browser
   - Click on "Budget" in the navigation menu

2. **Scroll to "Webhook Integration" section**

3. **Get a webhook URL from your automation service:**
   - **Zapier:** Create a new Zap ‚Üí Add "Webhooks by Zapier" trigger ‚Üí Copy the URL
   - **Make:** Add "Webhooks" module ‚Üí Copy the webhook URL
   - **IFTTT:** Create a new applet ‚Üí Add "Webhooks" trigger ‚Üí Copy the URL

4. **Paste the URL into SPLANTS:**
   - **Content Generated Webhook:** Triggered every time new content is created
   - **Content Published Webhook:** Triggered when content is published to a platform
   - **Daily Report Webhook:** Triggered once per day with usage summary

5. **Click "Save Webhook Settings"**

**Example Automations:**
- üìß Send email notification when content is generated
- üìä Add content to Google Sheets for tracking
- üí¨ Post to Slack when new content is ready
- üìÖ Create calendar events for scheduled posts
- üéØ Trigger marketing campaigns based on content creation

**No restart required!** Webhook settings are applied immediately.

---

### Task 8: Stop the System

**When you're done working:**

```bash
make stop
```

**This will:**
- Stop all services
- Free up your computer's memory
- Your data is safe (not deleted)

---

### Task 9: Start the System Again

**When you want to use it again:**

```bash
make start
```

**This will:**
- Start all services again
- Restore all your data
- Usually takes 30-60 seconds

---

### Task 10: Backup Your Content

**To save all your content:**

```bash
make backup
```

**This creates a compressed backup in the `backups/` folder**

---

### Task 11: Restore from Backup

**To restore content from a backup:**

```bash
make restore file=backups/splants_backup_20240101_120000.sql.gz
```

---

##  Troubleshooting

### Problem: "Docker is not running"

**Symptoms:**
- Error message: "Cannot connect to Docker daemon"
- Whale icon is not visible in system tray

**Solution:**

**Windows:**
1. Open Start Menu
2. Search for "Docker Desktop"
3. Click to open it
4. Wait for whale icon to appear
5. Try again

**Mac:**
1. Open Spotlight (Cmd + Space)
2. Type "Docker"
3. Press Enter
4. Wait for whale icon in menu bar
5. Try again

**Linux:**
```bash
sudo systemctl start docker
sudo systemctl enable docker
```

---

### Problem: "Cannot connect to Web UI at http://localhost:3000"

**Symptoms:**
- Browser shows "This site can't be reached"
- Error: "Connection refused"

**Solution:**

1. **Check if containers are running:**
```bash
docker-compose ps
```

2. **If nothing is running, start it:**
```bash
docker-compose up -d
```

3. **Wait 60 seconds, then check:**
```bash
docker-compose logs app
```

4. **Look for:** "SPLANTS Marketing Engine Ready!"

5. **If you see errors, try:**
```bash
docker-compose down
docker-compose up -d
```

---

### Problem: "Invalid API Key" error

**Symptoms:**
- 403 error
- Message: "Invalid API Key"

**Solution:**

1. **Check your `.env` file:**
```bash
cat .env | grep API_KEY
```

2. **Make sure `API_KEY` is set correctly**

3. **Restart the system:**
```bash
docker-compose restart app
```

4. **Make sure you're using the same key in your requests:**
   - Check your code or API docs "Authorize" button
   - The key should match what's in `.env`

---

### Problem: "OpenAI API error" or "Content generation failed"

**Symptoms:**
- 500 error when generating content
- Message mentions "OpenAI"

**Possible Causes & Solutions:**

**Cause 1: No OpenAI credit**
- Go to [platform.openai.com/account/billing](https://platform.openai.com/account/billing)
- Add more credit ($20 recommended)

**Cause 2: Wrong API key**
- Check your `.env` file
- Make sure `OPENAI_API_KEY` starts with `sk-`
- Copy the key directly from OpenAI (no extra spaces)

**Cause 3: API rate limit**
- OpenAI has usage limits
- Wait 60 seconds and try again
- Consider upgrading your OpenAI plan

**Check API key:**
```bash
cat .env | grep OPENAI_API_KEY
```

---

### Problem: Database connection failed

**Symptoms:**
- Error: "Database connection failed"
- System won't start

**Solution:**

1. **Check if database is running:**
```bash
docker-compose ps db
```

2. **If it's not running:**
```bash
docker-compose up -d db
```

3. **Wait 30 seconds, then start the app:**
```bash
docker-compose up -d app
```

4. **If still failing, reset the database:**
```bash
docker-compose down -v
docker-compose up -d
```

 **WARNING:** `-v` deletes all data. Backup first if needed!

---

### Problem: High costs / unexpected charges

**Symptoms:**
- OpenAI bills are higher than expected
- Budget alerts

**Solutions:**

1. **Set a monthly budget in `.env`:**
```env
MONTHLY_AI_BUDGET=50
```

2. **Set daily limits:**
```env
DAILY_API_LIMIT=100
```

3. **Enable Redis caching** (reduces costs by 30-50%):
   - Uncomment Redis in `docker-compose.yml`
   - Add to `.env`: `REDIS_URL=redis://redis:6379`
   - Restart: `docker-compose down && docker-compose up -d`

4. **Use shorter content:**
```json
{
  "length": 300  // instead of 1000
}
```

5. **Check your usage:**
   - Go to `http://localhost:3000` dashboard
   - Use "GET /v1/costs/usage"
   - Review spending patterns

---

### Problem: Port 3000 already in use

**Symptoms:**
- Error: "Port 3000 is already in use"

**Solution:**

**Option 1: Use a different port**

Edit `docker-compose.yml`:
```yaml
ports:
  - "3001:3000"  # Change 3000 to 3001 (or any free port)
```

Then access at `http://localhost:3001`

**Option 2: Stop the other service using port 3000**

**Windows:**
```bash
netstat -ano | findstr :3000
taskkill /PID [PID_NUMBER] /F
```

**Mac/Linux:**
```bash
lsof -i :3000
kill -9 [PID]
```

---

### Problem: Slow content generation

**Symptoms:**
- Takes longer than 30 seconds
- Timeout errors

**Solutions:**

1. **Reduce content length:**
```json
{
  "length": 500  // instead of 2000
}
```

2. **Don't use premium mode unless needed:**
```json
{
  "use_premium": false
}
```

3. **Check your internet connection**

4. **Check OpenAI status:**
   - Go to [status.openai.com](https://status.openai.com)
   - Check if there are outages

---

### Problem: Lost my API key

**Symptoms:**
- Can't find your OpenAI or system API key

**Solutions:**

**For OpenAI API Key:**
- You can't retrieve it, must create a new one
- Go to [platform.openai.com/api-keys](https://platform.openai.com/api-keys)
- Create new key
- Update `.env` file

**For System API Key:**
- It's in your `.env` file
- Check: `cat .env | grep ^API_KEY=`
- If lost, just create a new password:
  ```env
  API_KEY=new-secure-password-123
  ```
- Restart: `docker-compose restart`

---

##  Frequently Asked Questions

### General Questions

**Q: Do I need to know how to code?**
**A:** No! You can use the web interface at `http://localhost:3000` to do everything. No coding required.

**Q: Is this legal to use for my business?**
**A:** Yes! OpenAI grants you full rights to content generated through their API. You own the content.

**Q: Can I use this for client work?**
**A:** Absolutely! Many agencies use this to serve multiple clients efficiently.

**Q: Is my content private?**
**A:** Yes! Everything is stored in your private database. OpenAI doesn't train on API content.

**Q: Can multiple people use the same system?**
**A:** Yes, but you'll need to manage access through your API_KEY. Everyone can share the same installation.

---

### Technical Questions

**Q: What happens if I run out of OpenAI credit?**
**A:** Content generation will fail with an error message. Just add more credit to your OpenAI account.

**Q: Can I run this on a free server?**
**A:** Most free servers don't have enough resources. You need at least 2GB RAM and persistent storage.

**Q: How do I update to the latest version?**
**A:** 
```bash
git pull
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

**Q: Can I change the AI model?**
**A:** Yes! Edit `main.py` and change `gpt-4-turbo-preview` to another model like `gpt-3.5-turbo` (cheaper but lower quality).

**Q: How do I run this on the internet (not just localhost)?**
**A:** You need to deploy to a server. See `docs_DEPLOYMENT.md` for detailed instructions.

---

### Cost Questions

**Q: What if OpenAI raises prices?**
**A:** You can switch to alternative AI providers (Claude, Gemini, etc.). The system supports multiple providers.

**Q: How can I reduce costs?**
**A:**
1. Enable Redis caching (-30-50%)
2. Use shorter content
3. Set monthly budgets
4. Use GPT-3.5 instead of GPT-4 (much cheaper, lower quality)

**Q: What's the cheapest way to run this?**
**A:**
- Use your computer (free server)
- GPT-3.5-turbo ($10-15/month)
- No Redis ($0)
- **Total: ~$10-20/month**

**Q: What's the most powerful setup?**
**A:**
- VPS server ($15/month)
- GPT-4 + Claude multi-model ($50/month AI)
- Redis caching ($10/month)
- **Total: ~$75/month**

---

### Usage Questions

**Q: How long does content generation take?**
**A:** Usually 10-30 seconds per piece. Longer content takes more time.

**Q: Can I generate content in other languages?**
**A:** Yes! Just specify the language in your topic or add a note:
```json
{
  "topic": "Schreiben Sie einen Blogpost √ºber KI-Marketing (German)"
}
```

**Q: Can I customize the writing style?**
**A:** Yes! Use the `tone` parameter and add detailed instructions in your `topic`.

**Q: How many pieces can I generate per day?**
**A:** As many as you want! Limited only by:
- Your `DAILY_API_LIMIT` setting
- Your OpenAI credit
- Your budget

**Q: Can this schedule posts for me?**
**A:** The system prepares content and can schedule it, but actually posting requires platform API keys (optional feature).

---

### Troubleshooting Questions

**Q: What if I made a mistake in the .env file?**
**A:**
1. Edit the .env file
2. Save it
3. Run: `docker-compose restart app`

**Q: How do I see error messages?**
**A:**
```bash
docker-compose logs -f app
```

**Q: Can I reset everything and start fresh?**
**A:**
```bash
docker-compose down -v
docker-compose up -d
```
 This deletes all content!

**Q: Where are my generated contents stored?**
**A:** In the PostgreSQL database. To export:
```bash
docker-compose exec db pg_dump -U splants splants > export.sql
```

---

## üìö Glossary of Terms

### API (Application Programming Interface)
**Simple explanation:** A way for different programs to talk to each other.
**Example:** When you use the web interface, it's talking to the API, which talks to the AI.

### Docker
**Simple explanation:** A tool that packages software with everything it needs to run.
**Example:** Like a shipping container that has all the parts inside.

### Container
**Simple explanation:** An isolated environment where software runs.
**Example:** Like a virtual computer inside your computer.

### Docker Compose
**Simple explanation:** A tool that manages multiple containers at once.
**Example:** Starts your app container, database container, etc. all together.

### Database
**Simple explanation:** An organized place to store data.
**Example:** Like a digital filing cabinet for your content.

### PostgreSQL
**Simple explanation:** A type of database (the one this system uses).
**Example:** Think of it as Microsoft Access or Excel, but much more powerful.

### Redis
**Simple explanation:** Super-fast temporary storage (cache).
**Example:** Like sticky notes for quick access instead of searching through files.

### API Key
**Simple explanation:** A password that programs use to identify themselves.
**Example:** Like a membership card that lets you access a service.

### Environment Variables
**Simple explanation:** Settings stored in the `.env` file.
**Example:** Like preferences/settings for your software.

### Endpoint
**Simple explanation:** A specific URL that does one thing in the API.
**Example:** `/v1/generate` is an endpoint for generating content.

### JSON
**Simple explanation:** A format for organizing data.
**Example:** Like a structured form with fields and values.

### Port
**Simple explanation:** A "door" where programs communicate.
**Example:** Port 3000 is like apartment number 3000 in a building.

### localhost
**Simple explanation:** Your own computer.
**Example:** `localhost:8080` means port 8080 on your computer.

### GPT-4
**Simple explanation:** The AI model from OpenAI that generates content.
**Example:** Like the "brain" of the content generator.

### Token
**Simple explanation:** A piece of text (roughly 4 characters).
**Example:** "Hello world" is about 2 tokens. Used to measure AI usage.

### SEO (Search Engine Optimization)
**Simple explanation:** Making content show up better on Google.
**Example:** Using the right keywords so people can find your content.

### Webhook
**Simple explanation:** A way to automatically notify other services when something happens.
**Example:** Send a message to Slack when new content is generated.

### CLI (Command Line Interface)
**Simple explanation:** Using text commands instead of clicking buttons.
**Example:** Terminal/Command Prompt where you type commands.

### GUI (Graphical User Interface)
**Simple explanation:** Using buttons and visual elements (normal programs).
**Example:** The web interface at localhost:3000

---

## Reference Information

### Documentation Resources

1. **Primary Documentation:**
   - This README file
   - `docs_API_GUIDE.md` - Complete API reference
   - `docs_DEPLOYMENT.md` - Deployment procedures

2. **Diagnostic Tools:**
```bash
docker-compose logs -f app
```
Use this command to view application logs and error messages.

3. **System Testing:**
```bash
python test_api.py
```
This script validates all system features.

4. **System Status:**
Access the status endpoint at: `http://localhost:3000/api/v1/system/status`

### Interactive API Documentation

Access comprehensive API documentation at: `http://localhost:3000/api/docs`
- Complete feature reference
- Request/response examples
- Interactive testing interface
- No programming knowledge required

### External Resources

- **Docker Documentation:** [docs.docker.com](https://docs.docker.com)
- **OpenAI Documentation:** [platform.openai.com/docs](https://platform.openai.com/docs)
- **FastAPI Documentation:** [fastapi.tiangolo.com](https://fastapi.tiangolo.com)

---

## Next Steps

### Initial Configuration Complete

1. **Generate Content:**
   - Access `http://localhost:3000`
   - Use the `/v1/generate` endpoint

2. **Review Analytics:**
   - Access `/v1/analytics/dashboard`
   - View content statistics and performance metrics

3. **Explore Content Types:**
   - Social media posts
   - Email campaigns
   - Advertisement copy
   - Product descriptions

4. **Optional Enhancements:**
   - Configure webhooks for automation
   - Enable Redis caching (30-50% cost reduction)
   - Set up A/B testing for content optimization
   - Deploy to production server (see `docs_DEPLOYMENT.md`)

---

## üîí Security Best Practices

### Protecting Your API Keys

**Critical:** Never commit your `.env` file or share your API keys publicly!

1. **Environment Variables:**
   - Always keep API keys in the `.env` file (never in code)
   - The `.env` file is included in `.gitignore` for protection
   - Use different API keys for development and production

2. **System API Key:**
   - Generate a strong, unique API key (minimum 32 characters)
   - Use a password manager to store it securely
   - Rotate API keys regularly (every 90 days recommended)

3. **OpenAI API Key Security:**
   - Set spending limits in OpenAI dashboard
   - Monitor API usage regularly
   - Revoke and regenerate keys if compromised
   - Never share keys in screenshots, logs, or error messages

4. **Access Control:**
   - Limit who has access to the server/machine running SPLANTS
   - Use firewalls to restrict network access to trusted IPs
   - Consider using SSH key authentication for remote servers
   - Enable audit logging for production environments

5. **Docker Security:**
   - Keep Docker and all images updated
   - Don't expose unnecessary ports publicly
   - Use Docker secrets for sensitive data in production
   - Run containers with minimal privileges

6. **Database Security:**
   - Change default PostgreSQL password in production
   - Use strong database passwords (20+ characters)
   - Restrict database access to localhost only (unless needed)
   - Enable SSL/TLS for database connections in production

7. **Production Deployment:**
   - Use HTTPS/TLS for all web traffic
   - Implement rate limiting to prevent abuse
   - Set up monitoring and alerting for suspicious activity
   - Regular security updates and patches

**Emergency Response:**
If you believe your API keys have been compromised:
1. Immediately revoke the compromised keys
2. Generate new keys
3. Update your `.env` file
4. Restart the system: `make restart`
5. Monitor OpenAI billing for unauthorized usage

---

## üìä Data Retention and Privacy Policy

### Data Storage

**What Data is Stored:**
- Generated content (blog posts, social media, emails, etc.)
- Content metadata (creation date, type, quality scores)
- Analytics data (usage statistics, performance metrics)
- Cost tracking information
- A/B test results and webhook logs

**Where Data is Stored:**
- Local PostgreSQL database (on your server/computer)
- No data is sent to external services except:
  - OpenAI API (for content generation only)
  - Anthropic API (if premium mode enabled)
  - Configured webhooks (if enabled)

### Data Privacy

**Your Content is Private:**
- All generated content stays in your local database
- OpenAI does not use API data for model training
- No telemetry or usage tracking to external services
- You have full control and ownership of all content

**Third-Party Services:**
- **OpenAI:** See [OpenAI API Data Privacy](https://openai.com/policies/api-data-usage-policies)
- **Anthropic:** See [Anthropic Privacy Policy](https://www.anthropic.com/privacy)
- **Webhooks:** Data sent only to URLs you configure

### Data Retention

**Automatic Retention:**
- Content: Stored indefinitely by default
- Analytics: Aggregated monthly, kept indefinitely
- Logs: Rotated after 30 days (configurable)
- Backups: Manual creation/deletion (you control retention)

**Manual Data Management:**

1. **Backup Content:**
   ```bash
   make backup
   ```
   Creates timestamped backup in `backups/` folder

2. **Export Specific Content:**
   ```bash
   docker-compose exec db pg_dump -U splants splants -t contents > my-contents.sql
   ```

3. **Delete Old Content:**
   Access the database and delete by date:
   ```bash
   docker-compose exec db psql -U splants -d splants -c "DELETE FROM contents WHERE created_at < NOW() - INTERVAL '90 days';"
   ```

4. **Complete Data Deletion:**
   ```bash
   make clean  # WARNING: Deletes ALL data permanently
   ```

### GDPR Compliance

If you're subject to GDPR or handling EU user data:

1. **Data Subject Requests:**
   - Export: Use database export commands above
   - Delete: Use SQL commands to remove specific records
   - Audit: All operations logged in application logs

2. **Right to be Forgotten:**
   ```bash
   docker-compose exec db psql -U splants -d splants -c "DELETE FROM contents WHERE metadata->>'user_id' = 'USER_ID';"
   ```

3. **Data Processing Agreement:**
   - Review OpenAI's [DPA](https://openai.com/policies/data-processing-addendum)
   - Review Anthropic's privacy terms if using premium mode

4. **Recommended Retention Policy:**
   - Production content: 2 years
   - Test content: 90 days
   - Analytics data: 1 year
   - Logs: 30 days

### Backup Strategy

**Recommended Backup Schedule:**
- **Daily:** Automated database backup (use cron jobs)
- **Weekly:** Full system backup (database + configuration)
- **Monthly:** Archive backup to external storage

**Example Cron Job for Daily Backups:**
```bash
# Add to crontab: crontab -e
0 2 * * * cd /path/to/SPLANTS && make backup
```

**Backup Verification:**
```bash
# Test restore on a copy
docker-compose down
make restore file=backups/latest-backup.sql.gz
make test  # Verify system works
```

---

## License

This project is open source and available under the MIT License.

---

##  Acknowledgments

Built with:
- **FastAPI** - Modern Python web framework
- **OpenAI GPT-4** - AI content generation
- **PostgreSQL** - Reliable database
- **Docker** - Easy deployment
- **Anthropic Claude** - Optional premium AI

---

##  Version History

**v2.1 - Current (2025-11-12)**
-  Complete system with all features
-  Comprehensive documentation
-  Beginner-friendly setup
-  Cost controls and analytics
-  Security best practices documentation
-  Data retention and privacy policy

For detailed version history and changelog, see [CHANGELOG.md](CHANGELOG.md)

---

** for small businesses who want big marketing results**

*Questions? Check the FAQ section above or open an issue on GitHub!*

---

### Quick Reference Card

```
üìç Access Points:
‚îú‚îÄ Web UI: http://localhost:3000  üëà Start here!
‚îú‚îÄ API Docs: http://localhost:3000/api/docs
‚îú‚îÄ Health: http://localhost:3000/api/health
‚îî‚îÄ Status: http://localhost:3000/api/v1/system/status

Important Files:
‚îú‚îÄ .env - Configuration file (API keys)
‚îú‚îÄ docker-compose.yml - Service definitions
‚îú‚îÄ main.py - Main application code
‚îî‚îÄ requirements.txt - Python dependencies

Quick Commands:
‚îú‚îÄ Start: docker-compose up -d
‚îú‚îÄ Stop: docker-compose down
‚îú‚îÄ Logs: docker-compose logs -f app
‚îú‚îÄ Status: docker-compose ps
‚îú‚îÄ Restart: docker-compose restart
‚îú‚îÄ Backup: ./scripts_backup.sh
‚îî‚îÄ Test: python test_api.py

Cost Control:
‚îú‚îÄ Set budget in .env: MONTHLY_AI_BUDGET=50
‚îú‚îÄ Check usage: GET /v1/costs/usage
‚îî‚îÄ Enable caching: Uncomment Redis

Diagnostics:
‚îú‚îÄ Read troubleshooting section above
‚îú‚îÄ Check logs: docker-compose logs -f
‚îú‚îÄ Test API: python test_api.py
‚îî‚îÄ Review system status
```

---

**Note:** Reference this README and the API documentation at `http://localhost:3000/api/docs` for detailed information on all system features and capabilities.
